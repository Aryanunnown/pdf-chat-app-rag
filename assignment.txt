h part of the document the answer came
from”
Unclear aspects you must decide:- Page numbers? Exact quotes? Both?
Howdoyouextract relevant passages?- What if the answer synthesizes multiple
sections?- Should you show snippets in the UI?- How do you handle when LLM
hallucinates?
Option C: Document Comparison
Request: “Users want to compare two documents and find differ
ences/similarities”
Unclear aspects you must decide:- What kind of comparison? (content?
structure? conclusions?)- How do you visualize differences?- What if docu
ments are in different formats/styles?- How do you handle very long documents?- Should you do semantic comparison or literal text?
Deliverables
1. Deployed Application (REQUIRED)
• Live URL where we can test the app
• Works end-to-end (upload PDF → ask questions → get answers)
4
2. Source Code (REQUIRED)
• GitHub repository with clear commit history
• README with setup instructions
• Environment variables documented
3. Architecture Document (REQUIRED)
Create ARCHITECTURE.md explaining: (Expect the interviewer to act as your
student here, ELI5 things to them, this is part of culture at Regie)
Document Processing Strategy:- How do you extract text from PDFs?
How do you handle large documents?- Chunking strategy (if used)- Why you
chose this approach
LLM Integration:- Which provider and model did you choose? Why?- How
do you construct prompts?- Context management strategy- Cost optimization
techniques
Production Scenario Solutions:- For each scenario in Phase 2, document:
What broke in your initial implementation?- How you fixed it- Trade-offs you
made- What you’d improve with more time
Feature Extension Design:- Which feature did you choose? Why?- Design
decisions for ambiguous requirements- Assumptions you made- Limitations of
your implementation
4. Cost Analysis (REQUIRED)
Create COST_ANALYSIS.md: (We value this highly at Regie, even minor analysis
or idea of this will help)- Estimated cost per document upload- Estimated
cost per question- Estimated monthly cost for 1,000 users (10 docs/user, 50
questions/user)- How you’d reduce costs if needed
5. Demo Video (OPTIONAL but helpful)
• 2-3 minute screen recording showing:– Upload a document– Ask a few questions– Show any special features
Evaluation Criteria
1. Functionality (25%)
• Does it work end-to-end?
• Can we upload PDFs and get reasonable answers?
• Is the UI intuitive?
5
• Error handling?
2. System Design (25%)
• How did you structure the application?
• Appropriate technology choices?
• Scalable architecture?
• Cost-effective solution?
3. Problem Solving (25%)
• How did you handle production scenarios?
• Reasonable solutions to ambiguous requirements?
• Documented trade-offs?
• Honest about limitations?
4. Code Quality (15%)
• Clean, readable code?
• Appropriate error handling?
• Reasonable project structure?
• Documentation?
5. Communication (10%)
• Clear architecture document?
• Well-explained decisions?
• Good commit messages?
• Helpful README?
Interview Discussion Topics
Be prepared to discuss with Regie’s interviewer
Document Processing
1. Walk through your chunking strategy
• Why did you choose this approach?
• What’s the chunk size? Why?
• How do you handle chunk boundaries?
2. Large document handling
• Show me what happens with a 200-page PDF
• How do you prevent context window overflow?
• What’s your strategy for finding relevant sections?
6
LLM Integration
3. Prompt engineering
• Show me your actual prompts
• How do you prevent hallucinations?
• How do you ensure answers are grounded in the document?
4. Cost optimization
• Walk through your cost calculations
• Where are the biggest expenses?
• How would you reduce costs by 50%?
Live Debugging
5. We’ll give you a problematic PDF
• Upload it during the interview
• Debug issues in real-time
• Explain what’s going wrong
6. New requirement during interview
• “Now we need to support 100 documents per user”
• “Response time must be <2 seconds”
• “Cost must be <$0.01 per question”
• How would you modify your solution?
Design Decisions
7. Database choice
• Why did you choose [your database]?
• How are you storing documents?
• What about conversation history?
8. Feature extension
• Why did you pick [your chosen feature]?
• Walk through your implementation
• What would you do differently with more time?
Red Flags We’re Looking For
Signs of AI copy-paste without understanding:- Can’t explain why
they chose specific chunking strategy- Doesn’t understand cost implications- Can’t modify solution when we change requirements- Architecture document
is generic (not specific to their code)- Can’t explain trade-offs they made
Good signs:- Tested with real large PDFs and documented issues- Honest
about limitations- Can estimate costs accurately- Considered multiple ap
proaches and picked one- Can debug their own code in real-time
7
Common Pitfalls to Avoid
￿ Don’t:
• Send entire document with every question (cost explosion!)
• Use paid LLM APIs without considering costs
• Ignore large document scenarios
• Over-engineer with vector databases if simple chunking works
• Copy code without understanding it
￿ Do:
• Start simple, then optimize
• Test with real large PDFs
• Document your cost analysis
• Be honest about what doesn’t work
• Explain your reasoning
Time Management
Recommended breakdown:- Day 1 (8 hours): Core functionality (upload,
process, chat)- Day 2 (8 hours): Handle production scenarios, optimize- Day
3 (8 hours): Feature extension + documentation + deployment
If you’re spending more than 24 hours, you’re over-engineering. Focus on: 1.
Working end-to-end flow 2. Reasonable handling of large documents 3. Clear
documentation
Submission
1. GitHub Repository: Send us the link
2. Deployed URL: Where we can test it
3. Timeline: Submit within 3 days (72 hours) of receiving this
Include in your README:- Deployed URL- Setup instructions for local devel
opment- Environment variables needed- Any known limitations- Approximate
time spent
Technical Hints
PDF Text Extraction
// Node.js- pdf-parse (simple)
8
- pdf.js (more control)- PyPDF2 (Python)
Document Chunking Strategy
// Consider:- Chunk size: 500-1500 tokens typical- Overlap: 50-200 tokens between chunks- Semantic chunking: break at paragraphs/sentences
Cost Estimation Example
Groq (Llama 3.1 8B):- Input: FREE- Output: FREE- BUT: Rate limits (30 requests/minute)
Together AI (Llama 3.1 8B):- $0.18 per million input tokens- $0.18 per million output tokens- 1000 questions × 2000 tokens avg = $0.36
Context Management
// Naive approach:
systemPrompt + fullDocument + conversationHistory + question
// Problem: Too big!
// Better approach:
systemPrompt + relevantChunk + last2Messages + question
// How do you find relevantChunk?
Need Help?
• Technical issues: Email us if deployment/setup issues block you
• Clarifications: If something is genuinely blocking (vs intentionally am
biguous), ask
• Time concerns: Focus on core functionality first, extensions are sec
ondary
Final Notes
This assignment mirrors real AI product development:- Start with unclear
requirements- Discover edge cases through testing- Optimize for cost and
9
performance- Make pragmatic engineering decisions
We value:- Working software over perfect architecture- Honest analysis
over unrealistic claims- Clear thinking over complex solutions- Real testing
over theoretical approaches
Remember: We’re evaluating your problem-solving process, not expecting a
production-ready product in 3 days.
Good luck! We’re excited to see what you build.